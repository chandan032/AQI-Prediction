# -*- coding: utf-8 -*-
"""random-forest-regressor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f8Jchd-U5su3r5hJ5tDxhX5doQCk81lV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

combined_data = pd.read_csv('cleaned_data.csv')

combined_data.head()

X = combined_data.iloc[:, :-1]
y = combined_data.iloc[:, -1]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43)

"""## RANDOM FOREST REGRESSOR"""

from sklearn.ensemble import RandomForestRegressor
forest = RandomForestRegressor()
forest.fit(X_train, y_train)

f'Coefficient of determination R^2 on train set {forest.score(X_train, y_train)}'
# must be close to 1, 1 is perfect fit

f'Coefficient of determination R^2 on test set {forest.score(X_test, y_test)}'

"""### OVERFIT MODEL"""

from sklearn.model_selection import cross_val_score
score = cross_val_score(forest, X, y, cv = 3)

score.mean()

pred = forest.predict(X_test)

sns.distplot(y_test - pred)

"""#### HYPERPARAMETER TUNING"""

n_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(5, 30, num=6)]
min_samples_split = [2, 5, 10, 15, 20]
min_samples_leaf = [1, 2, 5, 10]
params = {
    'n_estimators': n_estimators,
    'max_features': max_features,
    'max_depth': max_depth,
    'min_samples_leaf': min_samples_split,
    'min_samples_leaf': min_samples_leaf
}

from sklearn.model_selection import RandomizedSearchCV
search = RandomizedSearchCV(forest, params, scoring='neg_mean_squared_error', 
                            cv=5, n_iter=100, random_state=43, n_jobs=-1)
search.fit(X,y)

search.best_params_

search.best_score_

pred = search.predict(X_test)
sns.distplot(y_test-pred)

from sklearn import metrics
print(f"Mean Abs Error: {metrics.mean_absolute_error(y_test, pred)}")
print(f"Mean Sq Error: {metrics.mean_squared_error(y_test, pred)}")
print(f"Root Mean Error: {np.sqrt(metrics.mean_squared_error(y_test, pred))}")

search.best_estimator_

import pickle
pickle.dump(search, open('random-forest.pkl', 'wb'))

